# **transaction-producer-service**
### **API Produtora de Transa√ß√µes**
A transaction-producer-service √© uma API respons√°vel por publicar transa√ß√µes financeiras, como dep√≥sitos e transfer√™ncias entre contas, em um t√≥pico Kafka. Faz parte de uma arquitetura de microservi√ßos, permitindo que outras partes do sistema consumam as transa√ß√µes para processamento posterior.
Com valida√ß√µes robustas, a API garante que apenas dados seguros e consistentes sejam enviados para o Kafka. Utilizando o Spring Kafka, ela facilita a integra√ß√£o com sistemas consumidores, promovendo escalabilidade e alta performance no processamento de transa√ß√µes financeiras em tempo real.
## **Principais Funcionalidades**
- ‚úâÔ∏è **Recebimento de Transa√ß√µes:**
    - Recebe informa√ß√µes sobre dep√≥sitos ou transfer√™ncia entre contas por meio de requisi√ß√µes HTTP.

- ‚úÖ **Valida√ß√£o de Dados:**
    - Valida detalhadamente os campos da requisi√ß√£o usando **Jakarta Bean Validation**, garantindo que apenas informa√ß√µes v√°lidas sejam publicadas.

- üì° **Envio para Kafka:**
    - Publica mensagens das transa√ß√µes em um t√≥pico Kafka configurado no sistema.

- üìú **Logs e Monitoramento:**
    - Registra opera√ß√µes utilizando logs para rastreamento e monitoramento.

## **Endpoints Dispon√≠veis**
### 1. **Dep√≥sito**
- **URL:** `/deposits`
- **M√©todo:** `POST`
- **Descri√ß√£o:** Realiza o dep√≥sito em uma conta espec√≠fica. Envia as informa√ß√µes para o respectivo t√≥pico Kafka.
- **Corpo da Requisi√ß√£o:**
``` json
  {
      "accountNumber": "123456",
      "branchCode": "001",
      "bankName": "Banco Exemplo",
      "accountType": "CORRENTE",
      "cpfCnpj": "12345678901",
      "owner": {
          "name": "Jo√£o Silva",
          "email": "joao@email.com"
      },
      "amount": 150.50
  }
```
### 2. **Transfer√™ncia**
- **URL:** `/transactions`
- **M√©todo:** `POST`
- **Descri√ß√£o:** Realiza uma transa√ß√£o de transfer√™ncia entre contas espec√≠ficas. Publica as informa√ß√µes no t√≥pico Kafka para processamento.
- **Corpo da Requisi√ß√£o:**
``` json
  {
      "accountNumber": "123456",
      "targetAccountNumber": "654321",
      "customerIdentifier": "12345678901",
      "amount": 250.75
  }
```
## **Como Executar o Projeto**
### 1. **Pr√©-requisitos**
- Java 17+.
- Apache Kafka configurado e em execu√ß√£o.
- Maven 3.x instalado.
## **Como Rodar Local**
- Basta apenas subir o docker-compose.yml que est√° no diretorio config

```
## **Estrutura de Diret√≥rios**
``` plaintext
src/
‚îú‚îÄ‚îÄ main/
‚îÇ   ‚îú‚îÄ‚îÄ java/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ com.example.transactionproducerservice
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ config/           # Configura√ß√µes (Kafka, Application)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Controller/       # Endpoints
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ domain/           # Modelos de Dominio (Ex.: DepositRequest, TransactionWithAccount)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Exception/        # Tratamento das Exce√ß√µes
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ Service/          # L√≥gica de neg√≥cio
‚îÇ   ‚îî‚îÄ‚îÄ resources/
‚îÇ       ‚îú‚îÄ‚îÄ application.yml       # Configura√ß√µes do ambiente
‚îî‚îÄ‚îÄ test/                         # Testes unit√°rios e de integra√ß√£o
```
## **Fluxo de Comunica√ß√£o da API**
Abaixo est√° o **fluxo simplificado** de como as requisi√ß√µes s√£o processadas pela API e enviadas para o Kafka:
1. O cliente realiza uma requisi√ß√£o HTTP com os dados da transa√ß√£o ou deposito.
2. A API recebe e valida os dados.
3. Ap√≥s valida√ß√£o, a transa√ß√£o ou o deposito √© enviada para o t√≥pico Kafka configurado.
4. Outros servi√ßos registrados no Kafka consomem as mensagens publicadas para processamento posterior.

## **Swagger**
 http://localhost:8080/producer-service/swagger-ui/index.html

## **Teste de Performance ‚Äì JMeter + VisualVM**
Por que testar localmente?
Avaliar lat√™ncia, consumo de recursos e impacto do Kafka antes da produ√ß√£o.

- JMeter simula carga e mede tempo de resposta, throughput e taxa de erros, verificando como sua API lida com m√∫ltiplas requisi√ß√µes simult√¢neas.
- VisualVM monitora CPU, mem√≥ria e threads, ajudando a identificar gargalos no processamento e otimizar o consumo de recursos.
- Profiling & Sampling no VisualVM revelam m√©todos lentos e aloca√ß√£o de objetos, permitindo ajustes na execu√ß√£o da API.
- Como o ambiente √© local e usa Docker, os testes ajudam a entender impactos como lat√™ncia e uso excessivo de mem√≥ria, ajustando a configura√ß√£o antes da produ√ß√£o.

Impacto do Docker
Rodar localmente pode gerar maior lat√™ncia e consumo devido √† virtualiza√ß√£o.
Testes garantem API est√°vel e eficiente antes do deploy.

## **An√°lise de Performance da API ‚Äì Testes Locais**
![img.png](img.png)
# Resumo
- 605.476 requisi√ß√µes processadas.
- Tempo m√©dio de resposta: 192ms.
- Throughput: 906.2 req/s.
- Taxa de erro: 0.62%.

Interpreta√ß√£o
- O desempenho geral parece s√≥lido, mas rodando localmente pode haver impactos devido a limita√ß√µes de hardware e concorr√™ncia no ambiente.
- Lat√™ncia pode estar influenciada pelo uso de rede local e container do Kafka, que adiciona sobrecarga ao processamento.

## **Monitoramento ‚Äì VisualVM**
![img_1.png](img_1.png)
   M√©tricas principais
- Uso de CPU: 34.7% ‚Äì relativamente baixo, mas pode aumentar dependendo da carga.
- Mem√≥ria Heap: 264MB em uso, com limite de ~4.2GB.
- Threads ativas: 227, com pico de 229.
- Coleta de lixo (GC): 0.1% ‚Äì indica boa gest√£o de mem√≥ria.

Impactos do ambiente local
- Rodando via Docker, o consumo de CPU e mem√≥ria pode variar dependendo da aloca√ß√£o de recursos feita no host.
- Como o Kafka tamb√©m est√° em container, pode gerar lat√™ncias adicionais dependendo da configura√ß√£o de volumes e networking.

## **Profiling ‚Äì VisualVM**
![img_2.png](img_2.png)
Ponto cr√≠tico identificado
- M√©todos de Controller consome 219.324 ms e representa 84.5% do tempo da thread.
- Poss√≠vel gargalo: Produ√ß√£o de mensagens no Kafka.

Raz√µes para tempo alto
- Como o ambiente est√° local, pode haver atraso na entrega das mensagens pelo produtor Kafka.
- O container do Kafka pode estar sofrendo com I/O disk lento ou limita√ß√£o de rede dentro do Docker.
- A serializa√ß√£o dos dados pode ser mais custosa dependendo do formato usado.
## **An√°lise de Aloca√ß√£o de Mem√≥ria ‚Äì VisualVM**
Monitoramento da Mem√≥ria ‚Äì Memory Sampler
![img_3.png](img_3.png)
- Total de threads ativas: 227, acumulando 27.3GB de mem√≥ria alocada.
- Thread de maior consumo: RMI TCP Connection(9)-192.000.000.00, utilizando 8.83GB (32.3% do total).
- Kafka Producer Thread (kafka-producer-network-thread) consumindo ~2.17GB (8% do total).
- Threads HTTP (http-nio-8080-exec) ocupando algumas centenas de MB cada.
- File Watcher e outras threads com consumo m√≠nimo (141KB), sem impacto relevante.

Impactos do ambiente local
- Como a aplica√ß√£o est√° rodando em um container Docker, o uso de mem√≥ria pode ser maior do que em produ√ß√£o, devido √† sobrecarga do ambiente virtualizado.
- O Kafka Producer tem um consumo significativo, possivelmente relacionado √† serializa√ß√£o dos dados ou √† espera na entrega das mensagens.
- A RMI TCP Connection apresenta um consumo elevado, indicando poss√≠vel troca intensa de objetos via rede ou algum mecanismo de comunica√ß√£o remota consumindo muitos recursos.

## **Aloca√ß√µes de mem√≥ria**
![img_4.png](img_4.png)
- byte[] ocupa 82.2MB (47.6% do total), com 283.758 inst√¢ncias.
- java.lang.Object[] consome 23.5MB (13.6% do total).
- char[] aparece com 14.7MB, indicando alto uso de strings.
- java.util.TreeMap$Entry consumindo 7.8MB, sugerindo estrutura de dados intensiva.
- int[] tamb√©m tem impacto, com 4.6MB de consumo.




